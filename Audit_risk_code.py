# -*- coding: utf-8 -*-
"""Fraudulent-frim-ml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zQL4w0zhmRv5Nu79GwtEMCpCwDbP4MLr
"""

!pip install gradio

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sn
import gradio as gr

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score ,confusion_matrix

from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

import warnings
warnings.filterwarnings(action='ignore')

"""# *Data Exploration*"""

dataset=pd.read_csv("audit_risk.csv")

dataset

dataset.describe()

"""## *Data Visualization*"""

for label in dataset.columns:
  plt.hist(dataset[dataset["Risk"]==1][label],color="blue",label="risk",alpha=0.7,density=True)
  plt.hist(dataset[dataset["Risk"]==0][label],color="red",label="No_risk",alpha=0.7,density=True)
  plt.title(label)
  plt.ylabel("Probabilty")
  plt.xlabel(label)
  plt.legend()
  plt.show()

dataset.info() #To Know dataType columns

dataset.isna().sum() #To know how many missing values

"""# Data Preprocessing

"""

df=dataset.copy()
#fill Missing Value
dataset['Money_Value'] = dataset['Money_Value'].fillna(dataset['Money_Value'].mean())
df['Money_Value'] = df['Money_Value'].fillna(df['Money_Value'].mean())

#One-hot encode the Location_ID Column
location_dummies=pd.get_dummies(df["LOCATION_ID"], prefix="location")
df=pd.concat([df,location_dummies],axis=1)
df=df.drop("LOCATION_ID",axis=1)

dataset.isna().sum()

df

#split data into X and Y
Y=df["Risk"]
X=df.drop("Risk",axis=1)

plt.figure(figsize=(30,25))
cor=X.corr()
sn.heatmap(cor,annot=True,cmap=plt.cm.CMRmap_r)
plt.show()

def corrlection(df,threshold):
  col_corr=set()
  corr_matrix=dataset.corr()
  for i in range(len(corr_matrix.columns)):
      for j in range(i):
           if abs(corr_matrix.iloc[i,j])>threshold:
                 colname=corr_matrix.columns[i]
                 col_corr.add(colname)
  return col_corr

corr_featur=corrlection(X,0.7)
len(set(corr_featur))
col=set(corr_featur)
print(col)

for label in X.columns:
  if label not in col:
    X=X.drop(label,axis=1)

X

Y

"""## *Creating Training Dataset & Test Dataset*"""

X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, shuffle=True)

X_train

#Scaler method
scaler = StandardScaler()
scaler.fit(X_train)
X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)
X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)

X_test

# Train multiple models
models = [('Logistic Regression', LogisticRegression()),
          ('Decision Tree', DecisionTreeClassifier()),
          ('Random Forest', RandomForestClassifier()),
           ("K-Nearest Neighbors", KNeighborsClassifier())]
''
# Fit the model on the training dataset
for name, model in models:
  model.fit(X_train,y_train)
  print(name)
  print()
  # Make predictions on the testing dataset
  y_pred = model.predict(X_test)

  # Evaluate the performance of the model
  print(classification_report(y_test, y_pred))
  print()

  cm=confusion_matrix(y_test,y_pred)
  print(cm)
  print()

"""# *Random Forest*"""

model2=RandomForestClassifier()
model2.fit(X_test,y_test)
y_pred=model2.predict(X_test)
print(y_pred)
print()
y_test_array=np.array(y_test)
print(y_test_array)

model2.fit(X,Y)
x_new=np.array([[0.168,	0.000,	0.84,	0.2,	1.0,	0.000,	0.4,	0.2,	0.0,	2.0,1.568,	0.4,	0.3136]])
y_new=model2.predict(x_new)
print(y_new)

# Commented out IPython magic to ensure Python compatibility.
import pydot
# %matplotlib inline
# Pull out one tree from the forest
Tree = model2.estimators_[5]
# Export the image to a dot file
from sklearn import tree
plt.figure(figsize=(15,10))
tree.plot_tree(Tree,filled=True,
              rounded=True,
              fontsize=14);

"""# *Gradio*"""

model = RandomForestClassifier()
model.fit(X, Y) # replace X and Y with your training data

# Define a function that uses your trained model to make predictions
def predict_risk(Risk_A,Risk_B,TOTAL,Score_B1,Risk_C,Risk_D,RiSk_E,Prob,	Risk_F,	Score	,Inherent_Risk,	CONTROL_RISK,	Audit_Risk):
    # Convert input features into a numpy array
    input_data = np.array([[Risk_A,Risk_B,TOTAL,Score_B1,Risk_C,	Risk_D,	RiSk_E,	Prob,Risk_F,Score,Inherent_Risk,CONTROL_RISK,	Audit_Risk]]) # add all the input features in a list

    # Make predictions using the trained model
    output = model.predict(input_data)


    # Return the prediction (convert 0/1 labels to risk/no-risk strings)
    if output == 0:
        return 'NO Risk'
    else:
        return 'RISK'

# Create a Gradio interface for the predict_risk function
inputs = [
    gr.inputs.Number(label="Risk_A"),
    gr.inputs.Number(label="Risk_B"),
    gr.inputs.Number(label="TOTAL"),
    gr.inputs.Number(label="Score_B.1"),
    gr.inputs.Number(label="Risk_C"),
    gr.inputs.Number(label="Risk_D"),
    gr.inputs.Number(label="Risk_E"),
    gr.inputs.Number(label="Prob"),
    gr.inputs.Number(label="Risk_F"),
    gr.inputs.Number(label="Score"),
    gr.inputs.Number(label="Inherent_Risk"),
    gr.inputs.Number(label="CONTROL_RISK"),
    gr.inputs.Number(label="Audit_Risk"),
]

output = gr.outputs.Textbox(label="Output")
iface = gr.Interface(fn=predict_risk,inputs=inputs, outputs=output)

# Launch the Gradio interface
iface.launch()

